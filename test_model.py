<<<<<<< HEAD
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import accuracy_score, classification_report
import numpy as np
import os
=======
# test_model.py
import pandas as pd
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import accuracy_score, classification_report
import torch
>>>>>>> 155009d (ğŸ‰ init:é¡¹ç›®åˆç‰ˆ)

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# åŠ è½½æµ‹è¯•æ•°æ®
test_df = pd.read_csv('test_data.csv')
print(f"æµ‹è¯•é›†å¤§å°: {len(test_df)}")

<<<<<<< HEAD
def predict_with_model(model_path, model_name):
    """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
    print(f"åŠ è½½{model_name}...")
    
    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.to(device)
    model.eval()
    
    predictions = []
    
    for i, text in enumerate(test_df['review_clean']):
        # ç¼–ç æ–‡æœ¬ï¼Œç¡®ä¿æˆªæ–­åˆ°æœ€å¤§é•¿åº¦
        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            max_length=128,
=======
# 1. æµ‹è¯•åŸºçº¿æ¨¡å‹ï¼ˆä½¿ç”¨ç½®ä¿¡åº¦åˆ’åˆ†ä¸‰åˆ†ç±»ï¼‰
print("åŠ è½½åŸºçº¿æ¨¡å‹...")
base_tokenizer = AutoTokenizer.from_pretrained('./chinese_bert')
base_model = AutoModelForSequenceClassification.from_pretrained('./chinese_bert')
base_model.to(device)

def score_to_label(score):
    """å°†ç½®ä¿¡åº¦åˆ†æ•°è½¬æ¢ä¸ºä¸‰åˆ†ç±»æ ‡ç­¾"""
    if score < 0.33:
        return 0  # å·®è¯„
    elif score < 0.66:
        return 1  # ä¸­è¯„
    else:
        return 2  # å¥½è¯„

def predict_with_model(model, tokenizer, texts):
    """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œå¤„ç†é•¿æ–‡æœ¬æˆªæ–­"""
    predictions = []
    for text in texts:
        # å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œç¡®ä¿æˆªæ–­åˆ°æœ€å¤§é•¿åº¦
        inputs = tokenizer(
            text, 
            return_tensors="pt", 
            truncation=True, 
            max_length=128,  # ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
>>>>>>> 155009d (ğŸ‰ init:é¡¹ç›®åˆç‰ˆ)
            padding=True
        )
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
<<<<<<< HEAD
        # é¢„æµ‹
        with torch.no_grad():
            outputs = model(**inputs)
            pred = torch.argmax(outputs.logits, dim=-1).item()
            predictions.append(pred)
            
        if i % 500 == 0:
            print(f"{model_name} å¤„ç†è¿›åº¦: {i}/{len(test_df)}")
    
    return predictions

# æµ‹è¯•åŸºçº¿æ¨¡å‹
print("\næµ‹è¯•åŸºçº¿æ¨¡å‹...")
base_preds = predict_with_model('./chinese_bert', 'åŸºçº¿æ¨¡å‹')

# æµ‹è¯•å®å¹³å‡æœ€ä½³æ¨¡å‹
print("\næµ‹è¯•å®å¹³å‡æœ€ä½³æ¨¡å‹...")
macro_preds = predict_with_model('./results/best_f1_macro', 'å®å¹³å‡æœ€ä½³æ¨¡å‹')

# æµ‹è¯•åŠ æƒå¹³å‡æœ€ä½³æ¨¡å‹
print("\næµ‹è¯•åŠ æƒå¹³å‡æœ€ä½³æ¨¡å‹...")
weighted_preds = predict_with_model('./results/best_f1_weighted', 'åŠ æƒå¹³å‡æœ€ä½³æ¨¡å‹')

# è®¡ç®—å‡†ç¡®ç‡
base_acc = accuracy_score(test_df['rating'], base_preds)
macro_acc = accuracy_score(test_df['rating'], macro_preds)
weighted_acc = accuracy_score(test_df['rating'], weighted_preds)

# è®¡ç®—åºå·
if os.path.exists('model_results.txt'):
    with open('model_results.txt', 'r', encoding='utf-8') as f:
        lines = f.readlines()
        count = sum(1 for line in lines if line.startswith('ç¬¬') and 'æ¬¡è¯„ä¼°' in line)
        eval_number = count + 1
else:
    eval_number = 1

# ä¿å­˜ç»“æœ
with open('model_results.txt', 'a', encoding='utf-8') as f:
    f.write(f"ç¬¬{eval_number}æ¬¡è¯„ä¼°\n")
    f.write(f"æµ‹è¯•é›†å¤§å°: {len(test_df)}\n")
    
    f.write("=== åŸºçº¿æ¨¡å‹ ===\n")
    f.write(f"å‡†ç¡®ç‡: {base_acc:.4f}\n\n")
    
    f.write("=== å®å¹³å‡æœ€ä½³æ¨¡å‹ ===\n")
    f.write(f"å‡†ç¡®ç‡: {macro_acc:.4f}\n")
    f.write(f"ç›¸æ¯”åŸºçº¿ - å‡†ç¡®ç‡æå‡: {macro_acc - base_acc:.4f}\n\n")
    
    f.write("=== åŠ æƒå¹³å‡æœ€ä½³æ¨¡å‹ ===\n")
    f.write(f"å‡†ç¡®ç‡: {weighted_acc:.4f}\n")
    f.write(f"ç›¸æ¯”åŸºçº¿ - å‡†ç¡®ç‡æå‡: {weighted_acc - base_acc:.4f}\n\n")
    
    f.write("åŸºçº¿æ¨¡å‹åˆ†ç±»æŠ¥å‘Š:\n")
    f.write(classification_report(test_df['rating'], base_preds, target_names=['å·®è¯„', 'ä¸­è¯„', 'å¥½è¯„'], digits=4))
    f.write("\nå®å¹³å‡æœ€ä½³æ¨¡å‹åˆ†ç±»æŠ¥å‘Š:\n")
    f.write(classification_report(test_df['rating'], macro_preds, target_names=['å·®è¯„', 'ä¸­è¯„', 'å¥½è¯„'], digits=4))
    f.write("\nåŠ æƒå¹³å‡æœ€ä½³æ¨¡å‹åˆ†ç±»æŠ¥å‘Š:\n")
    f.write(classification_report(test_df['rating'], weighted_preds, target_names=['å·®è¯„', 'ä¸­è¯„', 'å¥½è¯„'], digits=4))
    f.write("\n" + "=" * 50 + "\n\n")

print("è¯„ä¼°å®Œæˆï¼ç»“æœå·²è¿½åŠ åˆ° model_results.txt")
print(f"åŸºçº¿æ¨¡å‹å‡†ç¡®ç‡: {base_acc:.4f}")
print(f"å®å¹³å‡æœ€ä½³æ¨¡å‹å‡†ç¡®ç‡: {macro_acc:.4f}")
print(f"åŠ æƒå¹³å‡æœ€ä½³æ¨¡å‹å‡†ç¡®ç‡: {weighted_acc:.4f}")
print(f"å®å¹³å‡æ¨¡å‹ç›¸æ¯”åŸºçº¿æå‡: {macro_acc - base_acc:.4f}")
print(f"åŠ æƒå¹³å‡æ¨¡å‹ç›¸æ¯”åŸºçº¿æå‡: {weighted_acc - base_acc:.4f}")
=======
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
            pred = torch.argmax(probs, dim=-1).item()
            predictions.append(pred)
    
    return predictions

print("åŸºçº¿æ¨¡å‹é¢„æµ‹ä¸­...")
base_preds = predict_with_model(base_model, base_tokenizer, test_df['review_clean'].tolist())

# 2. æµ‹è¯•å¾®è°ƒæ¨¡å‹ï¼ˆç›´æ¥ä½¿ç”¨é¢„æµ‹æ ‡ç­¾ï¼‰
print("åŠ è½½å¾®è°ƒæ¨¡å‹...")
fine_tokenizer = AutoTokenizer.from_pretrained('./trained_model')
fine_model = AutoModelForSequenceClassification.from_pretrained('./trained_model')
fine_model.to(device)

print("å¾®è°ƒæ¨¡å‹é¢„æµ‹ä¸­...")
fine_preds = predict_with_model(fine_model, fine_tokenizer, test_df['review_clean'].tolist())

# 3. è®¡ç®—å‡†ç¡®ç‡
base_acc = accuracy_score(test_df['rating'], base_preds)
fine_acc = accuracy_score(test_df['rating'], fine_preds)

# 4. ä¿å­˜è¯„ä¼°ç»“æœ
with open('model_results.txt', 'w', encoding='utf-8') as f:
    f.write("å•†å“è¯„ä»·æƒ…æ„Ÿåˆ†ææ¨¡å‹è¯„ä¼°ç»“æœ\n")
    f.write("=" * 50 + "\n")
    f.write(f"æµ‹è¯•é›†å¤§å°: {len(test_df)}\n")
    f.write(f"åŸºçº¿æ¨¡å‹å‡†ç¡®ç‡: {base_acc:.4f}\n")
    f.write(f"å¾®è°ƒæ¨¡å‹å‡†ç¡®ç‡: {fine_acc:.4f}\n")
    f.write(f"å‡†ç¡®ç‡æå‡: {fine_acc - base_acc:.4f}\n\n")

    f.write("åŸºçº¿æ¨¡å‹åˆ†ç±»æŠ¥å‘Š:\n")
    f.write(classification_report(test_df['rating'], base_preds, target_names=['å·®è¯„', 'ä¸­è¯„', 'å¥½è¯„'], digits=4))
    f.write("\nå¾®è°ƒæ¨¡å‹åˆ†ç±»æŠ¥å‘Š:\n")
    f.write(classification_report(test_df['rating'], fine_preds, target_names=['å·®è¯„', 'ä¸­è¯„', 'å¥½è¯„'], digits=4))

print("è¯„ä¼°å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° model_results.txt")
print(f"åŸºçº¿æ¨¡å‹å‡†ç¡®ç‡: {base_acc:.4f}")
print(f"å¾®è°ƒæ¨¡å‹å‡†ç¡®ç‡: {fine_acc:.4f}")
print(f"å‡†ç¡®ç‡æå‡: {fine_acc - base_acc:.4f}")
>>>>>>> 155009d (ğŸ‰ init:é¡¹ç›®åˆç‰ˆ)
